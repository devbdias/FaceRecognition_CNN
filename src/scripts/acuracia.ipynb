{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m\n\u001b[0;32m     43\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     45\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     47\u001b[0m \u001b[39m# Treinamento do modelo\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m model\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49mconcatenate((known_images, unknown_images), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), \n\u001b[0;32m     49\u001b[0m           np\u001b[39m.\u001b[39;49mconcatenate((known_labels, unknown_labels), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), \n\u001b[0;32m     50\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[0;32m     51\u001b[0m           validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n\u001b[0;32m     53\u001b[0m \u001b[39m# Avaliação das imagens desconhecidas\u001b[39;00m\n\u001b[0;32m     54\u001b[0m predicted_probabilities \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39mconcatenate((known_images, unknown_images), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1683\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1680\u001b[0m split_at \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(math\u001b[39m.\u001b[39mfloor(batch_dim \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m validation_split)))\n\u001b[0;32m   1682\u001b[0m \u001b[39mif\u001b[39;00m split_at \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m split_at \u001b[39m==\u001b[39m batch_dim:\n\u001b[1;32m-> 1683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1684\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTraining data contains \u001b[39m\u001b[39m{batch_dim}\u001b[39;00m\u001b[39m samples, which is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1685\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msufficient to split it into a validation and training set as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1686\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mspecified by `validation_split=\u001b[39m\u001b[39m{validation_split}\u001b[39;00m\u001b[39m`. Either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1687\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprovide more data, or a different value for the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1688\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`validation_split` argument.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1689\u001b[0m             batch_dim\u001b[39m=\u001b[39mbatch_dim, validation_split\u001b[39m=\u001b[39mvalidation_split\n\u001b[0;32m   1690\u001b[0m         )\n\u001b[0;32m   1691\u001b[0m     )\n\u001b[0;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_split\u001b[39m(t, start, end):\n\u001b[0;32m   1694\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Carregando as bases de imagens conhecidas e desconhecidas\n",
    "known_dataset = glob.glob(r'src\\assets\\conhecidos\\*')\n",
    "unknown_dataset = glob.glob(r'src\\assets\\desconhecidos\\*')\n",
    "\n",
    "# Preprocessamento das imagens\n",
    "def preprocess_image(image):\n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Converte a imagem para escala de cinza\n",
    "        image = cv2.resize(image, (32,32)) # Redimensiona a imagem para 32x32\n",
    "        image = image.reshape((32, 32, 1)) # Adiciona um canal para a imagem\n",
    "    return image\n",
    "\n",
    "known_images = [cv2.imread(file) for file in known_dataset]\n",
    "known_images = [preprocess_image(image) for image in known_images if image is not None]\n",
    "\n",
    "unknown_images = [cv2.imread(file) for file in unknown_dataset]\n",
    "unknown_images = [preprocess_image(image) for image in unknown_images if image is not None]\n",
    "\n",
    "# Criação dos rótulos\n",
    "known_labels = np.arange(len(known_images))\n",
    "unknown_labels = np.ones(len(unknown_images))\n",
    "\n",
    "# Criação do modelo\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(len(known_images), activation='softmax'))\n",
    "\n",
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "model.fit(np.concatenate((known_images, unknown_images), axis=0), \n",
    "          np.concatenate((known_labels, unknown_labels), axis=0), \n",
    "          epochs=10, \n",
    "          validation_split=0.2)\n",
    "\n",
    "# Avaliação das imagens desconhecidas\n",
    "predicted_probabilities = model.predict(np.concatenate((known_images, unknown_images), axis=0))\n",
    "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
    "true_labels = np.concatenate((known_labels, unknown_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas adicionais\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "macro_precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "macro_recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "macro_f1 = f1_score(true_labels, predicted_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de desempenho\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Precisão (Weighted):\", precision)\n",
    "print(\"Recall (Weighted):\", recall)\n",
    "print(\"F1-score (Weighted):\", f1)\n",
    "print(\"Precisão (Macro):\", macro_precision)\n",
    "print(\"Recall (Macro):\", macro_recall)\n",
    "print(\"F1-score (Macro):\", macro_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
